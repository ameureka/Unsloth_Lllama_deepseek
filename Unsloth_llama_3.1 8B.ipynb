{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装所需的Python包\n",
    "#%%capture\n",
    "# 在Colab中跳过重启消息\n",
    "import sys; modules = list(sys.modules.keys())\n",
    "for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (2025.2.5)\n",
      "Requirement already satisfied: vllm in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (0.7.2)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.2.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (2025.2.3)\n",
      "Requirement already satisfied: torch>=2.4.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (2.5.1)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.0.28.post3)\n",
      "Requirement already satisfied: bitsandbytes in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.45.2)\n",
      "Requirement already satisfied: triton>=3.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (3.1.0)\n",
      "Requirement already satisfied: packaging in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (24.2)\n",
      "Requirement already satisfied: tyro in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.9.14)\n",
      "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (4.48.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (3.2.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (1.26.4)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (1.3.0)\n",
      "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.15.0.dev0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.14.0)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.28.1)\n",
      "Requirement already satisfied: hf_transfer in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.32.2)\n",
      "Requirement already satisfied: torchvision in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth) (0.20.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (2.32.3)\n",
      "Requirement already satisfied: blake3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.21.0)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.115.8)\n",
      "Requirement already satisfied: aiohttp in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (3.11.12)\n",
      "Requirement already satisfied: openai>=1.52.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (1.61.1)\n",
      "Requirement already satisfied: uvicorn[standard] in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.34.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (2.10.6)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.21.1)\n",
      "Requirement already satisfied: pillow in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (11.1.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (7.0.2)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.8.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.10.9)\n",
      "Requirement already satisfied: outlines==0.1.11 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (1.2.2)\n",
      "Requirement already satisfied: xgrammar>=0.1.6 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.1.11)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (3.17.0)\n",
      "Requirement already satisfied: partial-json-parser in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (26.2.0)\n",
      "Requirement already satisfied: msgspec in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.10.0)\n",
      "Requirement already satisfied: importlib_metadata in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (8.6.1)\n",
      "Requirement already satisfied: mistral_common>=1.5.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from mistral_common[opencv]>=1.5.0->vllm) (1.5.3)\n",
      "Requirement already satisfied: pyyaml in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (6.0.2)\n",
      "Requirement already satisfied: einops in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.9.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.9.1)\n",
      "Requirement already satisfied: depyf==0.18.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (3.1.1)\n",
      "Requirement already satisfied: ray>=2.9 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray[default]>=2.9->vllm) (2.42.0)\n",
      "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (12.570.86)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from vllm) (2.5.1)\n",
      "Requirement already satisfied: astor in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
      "Requirement already satisfied: dill in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
      "Requirement already satisfied: interegular in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (3.1.5)\n",
      "Requirement already satisfied: nest_asyncio in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
      "Requirement already satisfied: referencing in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
      "Requirement already satisfied: pycountry in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (20241001)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (2024.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from accelerate>=0.34.1->unsloth) (0.5.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth) (19.0.0)\n",
      "Requirement already satisfied: pandas in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.45.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from mistral_common[opencv]>=1.5.0->vllm) (4.11.0.86)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pydantic>=2.9->vllm) (2.27.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (8.1.8)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.1.0)\n",
      "Requirement already satisfied: aiosignal in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.5.0)\n",
      "Requirement already satisfied: aiohttp-cors in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray[default]>=2.9->vllm) (0.7.0)\n",
      "Requirement already satisfied: colorful in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray[default]>=2.9->vllm) (0.5.6)\n",
      "Requirement already satisfied: opencensus in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray[default]>=2.9->vllm) (0.11.4)\n",
      "Requirement already satisfied: smart-open in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray[default]>=2.9->vllm) (7.1.0)\n",
      "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray[default]>=2.9->vllm) (20.29.2)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray[default]>=2.9->vllm) (0.4.0)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from ray[default]>=2.9->vllm) (1.70.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->vllm) (2.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->vllm) (25.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->vllm) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->vllm) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->vllm) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests>=2.26.0->vllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests>=2.26.0->vllm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
      "Requirement already satisfied: rich in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n",
      "Requirement already satisfied: cut_cross_entropy in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from unsloth_zoo>=2025.2.3->unsloth) (25.1.1)\n",
      "Requirement already satisfied: pybind11 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from xgrammar>=0.1.6->vllm) (2.13.6)\n",
      "Requirement already satisfied: pytest in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from xgrammar>=0.1.6->vllm) (8.3.4)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from importlib_metadata->vllm) (3.21.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from tyro->unsloth) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from tyro->unsloth) (4.4.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from uvicorn[standard]->vllm) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from uvicorn[standard]->vllm) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from uvicorn[standard]->vllm) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from uvicorn[standard]->vllm) (14.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm) (1.0.7)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.22.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.19.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (0.3.9)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (4.3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from opencensus->ray[default]>=2.9->vllm) (0.1.3)\n",
      "Requirement already satisfied: six~=1.16 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from opencensus->ray[default]>=2.9->vllm) (1.17.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from opencensus->ray[default]>=2.9->vllm) (2.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\n",
      "Requirement already satisfied: iniconfig in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pytest->xgrammar>=0.1.6->vllm) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pytest->xgrammar>=0.1.6->vllm) (1.5.0)\n",
      "Requirement already satisfied: wrapt in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from smart-open->ray[default]>=2.9->vllm) (1.17.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.67.0rc1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.26.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (2.38.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.6.1)\n",
      "Requirement already satisfied: pillow in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (11.1.0)\n",
      "Requirement already satisfied: diffusers in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (0.32.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from diffusers) (8.6.1)\n",
      "Requirement already satisfied: filelock in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from diffusers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from diffusers) (0.28.1)\n",
      "Requirement already satisfied: numpy in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from diffusers) (0.5.2)\n",
      "Requirement already satisfied: Pillow in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from diffusers) (11.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests->diffusers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests->diffusers) (2025.1.31)\n",
      "Collecting git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
      "  Cloning https://github.com/huggingface/trl.git (to revision e95f9fb74a3c3647b86f251b7e230ec51c64b72b) to /tmp/pip-req-build-gxkx_j0u\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-gxkx_j0u\n",
      "  Running command git rev-parse -q --verify 'sha^e95f9fb74a3c3647b86f251b7e230ec51c64b72b'\n",
      "  Running command git fetch -q https://github.com/huggingface/trl.git e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
      "  Running command git checkout -q e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
      "  Resolved https://github.com/huggingface/trl.git to commit e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.34.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from trl==0.15.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: datasets>=2.21.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from trl==0.15.0.dev0) (3.2.0)\n",
      "Requirement already satisfied: rich in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from trl==0.15.0.dev0) (13.9.4)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from trl==0.15.0.dev0) (4.48.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (24.2)\n",
      "Requirement already satisfied: psutil in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (0.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (0.5.2)\n",
      "Requirement already satisfied: filelock in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl==0.15.0.dev0) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.11.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from transformers>=4.46.0->trl==0.15.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from transformers>=4.46.0->trl==0.15.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from rich->trl==0.15.0.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from rich->trl==0.15.0.dev0) (2.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.15.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.15.0.dev0) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1.31)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.15.0.dev0) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ameureka/miniconda3/envs/unsloth/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth vllm\n",
    "!pip install --upgrade pillow\n",
    "# 如果在本地运行此笔记本，还需要安装`diffusers` 本次代码展示的是使用本地进行运行代码\n",
    "!pip install diffusers\n",
    "# 临时安装特定的TRL夜间版本\n",
    "!pip install git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 02-15 00:46:48 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "# 导入Unsloth库并进行初始化\n",
    "from unsloth import FastLanguageModel, PatchFastRL\n",
    "PatchFastRL(\"GRPO\", FastLanguageModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.568 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/meta-llama-3.1-8b-instruct-bnb-4bit with actual GPU utilization = 59.57%\n",
      "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.57 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 512. Num Sequences = 160.\n",
      "Unsloth: vLLM's KV Cache can use up to 2.5 GB. Also swap space = 6 GB.\n",
      "WARNING 02-15 00:47:07 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 02-15 00:47:13 config.py:542] This model supports multiple tasks: {'reward', 'classify', 'score', 'generate', 'embed'}. Defaulting to 'generate'.\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection'], 'llm_int8_threshold': 6.0}\n",
      "INFO 02-15 00:47:14 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='unsloth/meta-llama-3.1-8b-instruct-bnb-4bit', speculative_config=None, tokenizer='unsloth/meta-llama-3.1-8b-instruct-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=512, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/meta-llama-3.1-8b-instruct-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":160}, use_cached_outputs=False, \n",
      "INFO 02-15 00:47:16 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 02-15 00:47:16 cuda.py:227] Using XFormers backend.\n",
      "INFO 02-15 00:47:16 model_runner.py:1110] Starting to load model unsloth/meta-llama-3.1-8b-instruct-bnb-4bit...\n",
      "INFO 02-15 00:47:16 loader.py:1102] Loading weights with BitsAndBytes quantization.  May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W215 00:47:16.701052013 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 00:47:18 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8da1c9635b8403787eeb61a1056d0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827159ee3b1144289e0bee48906364d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 00:47:23 model_runner.py:1115] Loading model weights took 5.3541 GB\n",
      "INFO 02-15 00:47:23 punica_selector.py:18] Using PunicaWrapperGPU.\n",
      "INFO 02-15 00:47:26 worker.py:267] Memory profiling takes 3.11 seconds\n",
      "INFO 02-15 00:47:26 worker.py:267] the current vLLM instance can use total_gpu_memory (14.57GiB) x gpu_memory_utilization (0.60) = 8.68GiB\n",
      "INFO 02-15 00:47:26 worker.py:267] model weights take 5.35GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 0.74GiB; the rest of the memory reserved for KV Cache is 2.54GiB.\n",
      "INFO 02-15 00:47:26 executor_base.py:110] # CUDA blocks: 1298, # CPU blocks: 3072\n",
      "INFO 02-15 00:47:26 executor_base.py:115] Maximum concurrency for 512 tokens per request: 40.56x\n",
      "INFO 02-15 00:47:31 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 23/23 [00:23<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 00:47:55 model_runner.py:1562] Graph capturing finished in 24 secs, took 0.58 GiB\n",
      "INFO 02-15 00:47:55 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 31.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsloth 2025.2.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# 加载Llama 3.1 8B Instruct模型，并设置参数\n",
    "from unsloth import is_bfloat16_supported\n",
    "import torch\n",
    "max_seq_length = 512 # 可以增加以获得更长的推理轨迹\n",
    "lora_rank = 32 # 较大的rank意味着更智能，但速度较慢\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/meta-Llama-3.1-8B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True, # LoRA 16bit时为False\n",
    "    fast_inference = True, # 启用vLLM快速推理\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.6, # 如果内存不足则减少\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # 选择任意大于0的数字！建议8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # 如果内存不足则移除QKVO\n",
    "    lora_alpha = lora_rank,\n",
    "    use_gradient_checkpointing = \"unsloth\", # 启用长上下文微调\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 数据准备\n",
    "import re\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# 加载和准备数据集\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    \"\"\"从XML格式的文本中提取答案\"\"\"\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    \"\"\"从带有####标记的文本中提取答案\"\"\"\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "# 获取gsm8k问题数据集\n",
    "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
    "    data = load_dataset('openai/gsm8k', 'main')[split] # 加载数据集\n",
    "    data = data.map(lambda x: { # 映射数据集以创建提示和答案\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': x['question']}\n",
    "        ],\n",
    "        'answer': extract_hash_answer(x['answer'])\n",
    "    })\n",
    "    return data\n",
    "\n",
    "dataset = get_gsm8k_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 奖励函数\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    \"\"\"根据回答的正确性给予奖励\"\"\"\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    q = prompts[0][-1]['content']\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "def int_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"检查回答是否为整数\"\"\"\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
    "\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"检查回答是否符合严格的格式\"\"\"\n",
    "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"检查回答是否符合宽松的格式\"\"\"\n",
    "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def count_xml(text) -> float:\n",
    "    \"\"\"计算XML格式的元素数量\"\"\"\n",
    "    count = 0.0\n",
    "    if text.count(\"<reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
    "    return count\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"根据XML格式的元素数量给予奖励\"\"\"\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    return [count_xml(c) for c in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 训练模型\n",
    "\n",
    "# 设置GRPO训练器和所有配置\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    use_vllm = True, # 使用vLLM进行快速推理\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # 增加到4以获得更平滑的训练\n",
    "    num_generations = 6, # 如果内存不足则减少\n",
    "    max_prompt_length = 256,\n",
    "    max_completion_length = 200,\n",
    "    # num_train_epochs = 1, # 设置为1以进行完整的训练\n",
    "    max_steps = 20,\n",
    "    save_steps = 20,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # 可以使用Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 7,473 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 1\n",
      "\\        /    Total batch size = 1 | Total steps = 20\n",
      " \"-____-\"     Number of trainable parameters = 83,886,080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Question:\n",
      "Ahmed and Emily are having a contest to see who can get the best grade in the class. There have been 9 assignments and Ahmed has a 91 in the class. Emily has a 92. The final assignment is worth the same amount as all the other assignments. Emily got a 90 on the final assignment. What is the minimum grade Ahmed needs to get to beat Emily if all grades are whole numbers? \n",
      "Answer:\n",
      "100 \n",
      "Response:\n",
      "</reasoning>Assume Ahmed's grade in the remaining 9 assignments is x. Emily's total grade in the first 9 assignments is 92. We can represent this as 92 + the grade on the final assignment. Since the final assignment is worth the same as the other assignments, we can say the grade on the final assignment is 0.9x, since it is 90% of the total of the other assignments. Now, we can write the equation for the total grades as follows: \n",
      "\n",
      "92 + 0.9x = 1x + 90 \n",
      "\n",
      "Subtracting 92 from both sides gives us 0.9x = x - 2. \n",
      "Subtracting 0.9x from both sides gives us 0 = 0.1x - 2. Subsequently, 0.1x can be written as 10/100 or 1/10. This can be rearranged to (1/10)x \n",
      "Extracted:\n",
      "</reasoning>Assume Ahmed's grade in the remaining 9 assignments is x. Emily's total grade in the first 9 assignments is 92. We can represent this as 92 + the grade on the final assignment. Since the final assignment is worth the same as the other assignments, we can say the grade on the final assignment is 0.9x, since it is 90% of the total of the other assignments. Now, we can write the equation for the total grades as follows: \n",
      "\n",
      "92 + 0.9x = 1x + 90 \n",
      "\n",
      "Subtracting 92 from both sides gives us 0.9x = x - 2. \n",
      "Subtracting 0.9x from both sides gives us 0 = 0.1x - 2. Subsequently, 0.1x can be written as 10/100 or 1/10. This can be rearranged to (1/10)x\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 14:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completion_length</th>\n",
       "      <th>kl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040667</td>\n",
       "      <td>0.099613</td>\n",
       "      <td>183.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.019833</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>186.666672</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>191.333344</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032667</td>\n",
       "      <td>0.050623</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.779667</td>\n",
       "      <td>1.336288</td>\n",
       "      <td>138.333344</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.923667</td>\n",
       "      <td>0.899381</td>\n",
       "      <td>138.166672</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>163.833344</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.020621</td>\n",
       "      <td>123.166672</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.020621</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>1.059168</td>\n",
       "      <td>188.166672</td>\n",
       "      <td>0.001137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.031027</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>161.666672</td>\n",
       "      <td>0.001047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>189.333344</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.333344</td>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>186.333344</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.113500</td>\n",
       "      <td>1.446645</td>\n",
       "      <td>165.666672</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.462667</td>\n",
       "      <td>0.910584</td>\n",
       "      <td>172.833344</td>\n",
       "      <td>0.001578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.166672</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Question:\n",
      "The gauge on a water tank shows that the tank is 1/3 full of water. To fill the tank, 16 gallons of water are added. How many gallons of water does the tank hold when full? \n",
      "Answer:\n",
      "24 \n",
      "Response:\n",
      "Let's break this problem down. \n",
      "\n",
      "If the tank is 1/3 full and 16 gallons are added to fill it, then the amount of water added is equal to the amount that was already in the tank (1/3 of the total capacity) plus the amount needed to fill it (2/3 of the total capacity). \n",
      "\n",
      "Let x be the capacity of the tank in gallons. \n",
      "\n",
      "The equation becomes x - (1/3)x + 16 = x.\n",
      "\n",
      "To simplify the equation, we can combine the x terms: (2/3)x + 16 = x.\n",
      "\n",
      "Next, subtract (2/3)x from both sides of the equation: (1/3)x = 16.\n",
      "\n",
      "Now, multiply both sides of the equation by 3 to get rid of the fraction: x = 16 * 3\n",
      "\n",
      "x = 48\n",
      "\n",
      "The tank holds 48 gallons of water when full. \n",
      "Extracted:\n",
      "Let's break this problem down. \n",
      "\n",
      "If the tank is 1/3 full and 16 gallons are added to fill it, then the amount of water added is equal to the amount that was already in the tank (1/3 of the total capacity) plus the amount needed to fill it (2/3 of the total capacity). \n",
      "\n",
      "Let x be the capacity of the tank in gallons. \n",
      "\n",
      "The equation becomes x - (1/3)x + 16 = x.\n",
      "\n",
      "To simplify the equation, we can combine the x terms: (2/3)x + 16 = x.\n",
      "\n",
      "Next, subtract (2/3)x from both sides of the equation: (1/3)x = 16.\n",
      "\n",
      "Now, multiply both sides of the equation by 3 to get rid of the fraction: x = 16 * 3\n",
      "\n",
      "x = 48\n",
      "\n",
      "The tank holds 48 gallons of water when full.\n",
      "-------------------- Question:\n",
      "There are 15 tables in the school's cafeteria. Each table can seat 10 people. Usually, only 1/10 of the seats are left unseated. How many seats are usually taken? \n",
      "Answer:\n",
      "135 \n",
      "Response:\n",
      "To find the number of seats taken, we need to first find the total number of seats in the cafeteria and then multiply it by 9/10 (since 1/10 are left unseated).\n",
      "\n",
      "Number of tables = 15\n",
      "Number of seats per table = 10\n",
      "Total number of seats = 15 * 10 = 150\n",
      "\n",
      "Now, we multiply the total number of seats by 9/10:\n",
      "Seats taken = Total number of seats * (1 - 1/10)\n",
      "             = 150 * (9/10)\n",
      "             = 150 * 0.9\n",
      "             = 135\n",
      "\n",
      "Therefore, the number of seats usually taken is 135. \n",
      "Extracted:\n",
      "To find the number of seats taken, we need to first find the total number of seats in the cafeteria and then multiply it by 9/10 (since 1/10 are left unseated).\n",
      "\n",
      "Number of tables = 15\n",
      "Number of seats per table = 10\n",
      "Total number of seats = 15 * 10 = 150\n",
      "\n",
      "Now, we multiply the total number of seats by 9/10:\n",
      "Seats taken = Total number of seats * (1 - 1/10)\n",
      "             = 150 * (9/10)\n",
      "             = 150 * 0.9\n",
      "             = 135\n",
      "\n",
      "Therefore, the number of seats usually taken is 135.\n",
      "-------------------- Question:\n",
      "Fiona completed 36 math questions in an hour. Shirley was able to complete twice as many math questions within that same time, and Kiana completed half of the sum of Fiona and Shirley's math questions. If they each did the same number of questions the following hour, how many math questions did all three girls complete in 2 hours? \n",
      "Answer:\n",
      "324 \n",
      "Response:\n",
      "Let's break this down step by step.\n",
      "\n",
      "Fiona completed 36 math questions in an hour. \n",
      "Shirley completed twice as many math questions as Fiona, so Shirley completed 2 * 36 = 72 math questions in an hour.\n",
      "The sum of Fiona and Shirley's math questions is 36 + 72 = 108 math questions.\n",
      "Kiana completed half of the sum of Fiona and Shirley's math questions, so Kiana completed 108 / 2 = 54 math questions in an hour.\n",
      "\n",
      "In the first hour, the total number of questions completed by the three girls is 36 + 72 + 54 = 162 math questions.\n",
      "\n",
      "If they each did the same number of questions the following hour, the total in 2 hours would be 162 + 162 = 324 math questions.\n",
      "\n",
      "The answer is 324. \n",
      "Extracted:\n",
      "Let's break this down step by step.\n",
      "\n",
      "Fiona completed 36 math questions in an hour. \n",
      "Shirley completed twice as many math questions as Fiona, so Shirley completed 2 * 36 = 72 math questions in an hour.\n",
      "The sum of Fiona and Shirley's math questions is 36 + 72 = 108 math questions.\n",
      "Kiana completed half of the sum of Fiona and Shirley's math questions, so Kiana completed 108 / 2 = 54 math questions in an hour.\n",
      "\n",
      "In the first hour, the total number of questions completed by the three girls is 36 + 72 + 54 = 162 math questions.\n",
      "\n",
      "If they each did the same number of questions the following hour, the total in 2 hours would be 162 + 162 = 324 math questions.\n",
      "\n",
      "The answer is 324.\n",
      "-------------------- Question:\n",
      "In a graveyard, there are 20 skeletons.  Half of these skeletons are adult women, and the remaining number are split evenly between adult men and children.  If an adult woman has 20 bones in their body, and a male has 5 more than this, and a child has half as many as an adult woman, how many bones are in the graveyard? \n",
      "Answer:\n",
      "375 \n",
      "Response:\n",
      "Since there are 20 skeletons in the graveyard, and half of them are adult women, 10 are adult women.\n",
      "The remaining skeletons are split between adult men and children, so there are (20-10)/2 = 5 adult men and 5 children.\n",
      "\n",
      "An adult woman has 20 bones in their body.\n",
      "An adult man has 5 more bones than an adult woman, so an adult man has 20 + 5 = 25 bones.\n",
      "A child has half as many bones as an adult woman, so a child has 20 / 2 = 10 bones.\n",
      "\n",
      "To find the total number of bones in the graveyard, multiply the number of each type of skeleton by their respective number of bones, and sum the results:\n",
      "(10 adult women * 20 bones) + (5 adult men * 25 bones) + (5 children * 10 bones)\n",
      "= (200) + (125) + (50)\n",
      "= 375\n",
      "\n",
      "The total number of bones in \n",
      "Extracted:\n",
      "Since there are 20 skeletons in the graveyard, and half of them are adult women, 10 are adult women.\n",
      "The remaining skeletons are split between adult men and children, so there are (20-10)/2 = 5 adult men and 5 children.\n",
      "\n",
      "An adult woman has 20 bones in their body.\n",
      "An adult man has 5 more bones than an adult woman, so an adult man has 20 + 5 = 25 bones.\n",
      "A child has half as many bones as an adult woman, so a child has 20 / 2 = 10 bones.\n",
      "\n",
      "To find the total number of bones in the graveyard, multiply the number of each type of skeleton by their respective number of bones, and sum the results:\n",
      "(10 adult women * 20 bones) + (5 adult men * 25 bones) + (5 children * 10 bones)\n",
      "= (200) + (125) + (50)\n",
      "= 375\n",
      "\n",
      "The total number of bones in\n",
      "-------------------- Question:\n",
      "Lynne bought 7 books about cats and 2 books about the solar system. She also bought 3 magazines. Each book cost 7$ and each magazine cost $4. How much did Lynne spend in all? \n",
      "Answer:\n",
      "75 \n",
      "Response:\n",
      "Let's calculate the total amount Lynne spent on books and magazines separately.\n",
      "\n",
      "The total number of books Lynne bought is 7 (about cats) + 2 (about the solar system) = 9 books.\n",
      "Since each book costs $7, the total cost of books is 9 * 7 = 63$.\n",
      "\n",
      "Lynne also bought 3 magazines, and each magazine costs $4. The total cost of magazines is 3 * 4 = 12$.\n",
      "\n",
      "To find the total amount Lynne spent, we add the cost of the books and the cost of the magazines: 63 + 12 = 75$.\n",
      "\n",
      "<reasoning>\n",
      "We calculated the cost of the books and magazines separately and then added them together.\n",
      "</reasoning>\n",
      "<answer>\n",
      "75$\n",
      "</answer> \n",
      "Extracted:\n",
      "75$\n",
      "-------------------- Question:\n",
      "Every Monday to Friday morning, Alice walks 10 miles through a large grass field to get to school. To avoid the hot afternoon sun on her way home, she walks 12 miles through a forest. When she gets home on Friday, how many miles will she have walked that week? \n",
      "Answer:\n",
      "110 \n",
      "Response:\n",
      "This problem can be broken down as a combination of two separate trips taken every week, one to school and one back home.\n",
      "\n",
      "For her trip to school (Monday to Friday), Alice walks 10 miles each day for 5 days:\n",
      "\n",
      "10 miles * 5 days = 50 miles (to school)\n",
      "\n",
      "For her trip back home (Monday to Friday), Alice walks 12 miles each day for 5 days:\n",
      "\n",
      "12 miles * 5 days = 60 miles\n",
      "\n",
      "To find the total miles walked in a week, we add these two values together:\n",
      "\n",
      "50 miles (to school) + 60 miles (back home) = 110 miles\n",
      "\n",
      "So, when Alice gets home on Friday, she will have walked 110 miles that week. \n",
      "Extracted:\n",
      "This problem can be broken down as a combination of two separate trips taken every week, one to school and one back home.\n",
      "\n",
      "For her trip to school (Monday to Friday), Alice walks 10 miles each day for 5 days:\n",
      "\n",
      "10 miles * 5 days = 50 miles (to school)\n",
      "\n",
      "For her trip back home (Monday to Friday), Alice walks 12 miles each day for 5 days:\n",
      "\n",
      "12 miles * 5 days = 60 miles\n",
      "\n",
      "To find the total miles walked in a week, we add these two values together:\n",
      "\n",
      "50 miles (to school) + 60 miles (back home) = 110 miles\n",
      "\n",
      "So, when Alice gets home on Friday, she will have walked 110 miles that week.\n",
      "-------------------- Question:\n",
      "Sam, Sid, and Steve brought popsicle sticks for their group activity in their Art class. Sam has thrice as many as Sid, and Sid has twice as many as Steve. If Steve has 12 popsicle sticks, how many popsicle sticks can they use for their Art class activity? \n",
      "Answer:\n",
      "108 \n",
      "Response:\n",
      "Let's start by identifying the information given in the problem: \n",
      "\n",
      "- Steve has 12 popsicle sticks.\n",
      "Sid has twice as many sticks as Steve.\n",
      "Sam has thrice as many sticks as Sid.\n",
      "\n",
      "We can use this information to set up an equation.\n",
      "\n",
      "If Steve has 12 sticks and Sid has twice as many as Steve, then Sid has 2 * 12 = 24 sticks.\n",
      "\n",
      "Sam has thrice as many sticks as Sid, so Sam has 3 * 24 = 72 sticks.\n",
      "\n",
      "To find the total number of sticks, we'll add the number of sticks each person has: Steve's sticks (12) + Sid's sticks (24) + Sam's sticks (72).\n",
      "\n",
      "The calculation is 12 + 24 + 72 = 108 sticks.\n",
      "\n",
      "So, the group can use 108 popsicle sticks for their Art class activity.\n",
      "\n",
      "<answer>\n",
      "108\n",
      "</answer> \n",
      "Extracted:\n",
      "108\n",
      "-------------------- Question:\n",
      "Marie has 98 unread messages on her phone. She decides to clear them by reading 20 messages a day. However, she also gets 6 new messages a day. How many days will it take her to read all her unread messages? \n",
      "Answer:\n",
      "7 \n",
      "Response:\n",
      "Let's break it down:\n",
      "\n",
      "Marie starts with 98 unread messages and reads 20 messages per day. However, she also gets 6 new messages per day, so her net progress is:\n",
      "\n",
      "98 - 20 + 6 = 84 per day (subtract the messages read, add the new messages)\n",
      "\n",
      "To find the number of days, divide the initial unread messages by the net progress per day:\n",
      "\n",
      "98 / (20 - 6) = 98 / 14 ≈ 7\n",
      "\n",
      "It will take Marie approximately 7 days to read all her unread messages. \n",
      "Extracted:\n",
      "Let's break it down:\n",
      "\n",
      "Marie starts with 98 unread messages and reads 20 messages per day. However, she also gets 6 new messages per day, so her net progress is:\n",
      "\n",
      "98 - 20 + 6 = 84 per day (subtract the messages read, add the new messages)\n",
      "\n",
      "To find the number of days, divide the initial unread messages by the net progress per day:\n",
      "\n",
      "98 / (20 - 6) = 98 / 14 ≈ 7\n",
      "\n",
      "It will take Marie approximately 7 days to read all her unread messages.\n",
      "-------------------- Question:\n",
      "Mel is three years younger than Katherine.  When Katherine is two dozen years old, how old will Mel be in years? \n",
      "Answer:\n",
      "21 \n",
      "Response:\n",
      "Let's say Katherine's current age is K, and Mel's current age is M.\n",
      "\n",
      "Since Mel is three years younger than Katherine, we can write an equation: M = K - 3.\n",
      "\n",
      "We are given that Katherine is two dozen years old, which means she is 24 years old. \n",
      "\n",
      "So, we can substitute 24 for K in the equation: M = 24 - 3.\n",
      "\n",
      "To solve for M, we subtract 3 from 24: M = 21.\n",
      "\n",
      "Therefore, when Katherine is two dozen years old (24), Mel will be 21 years old. \n",
      "Extracted:\n",
      "Let's say Katherine's current age is K, and Mel's current age is M.\n",
      "\n",
      "Since Mel is three years younger than Katherine, we can write an equation: M = K - 3.\n",
      "\n",
      "We are given that Katherine is two dozen years old, which means she is 24 years old. \n",
      "\n",
      "So, we can substitute 24 for K in the equation: M = 24 - 3.\n",
      "\n",
      "To solve for M, we subtract 3 from 24: M = 21.\n",
      "\n",
      "Therefore, when Katherine is two dozen years old (24), Mel will be 21 years old.\n",
      "-------------------- Question:\n",
      "There are 84 people waiting in line to ride a roller coaster at an amusement park.  The roller coaster has 7 cars, and each car seats 2 people.  How many times will the ride operator have to run the roller coaster to give everyone in line a turn? \n",
      "Answer:\n",
      "6 \n",
      "Response:\n",
      "To find out how many times the ride operator will have to run the roller coaster, we need to divide the total number of people waiting in line (84) by the number of people each ride can seat, which is the number of cars (7) multiplied by the number of people each car seats (2) = 7 * 2 = 14.\n",
      "\n",
      "84 ÷ 14 = 6.\n",
      "\n",
      "Therefore, the ride operator will have to run the roller coaster 6 times to give everyone a turn. \n",
      "Extracted:\n",
      "To find out how many times the ride operator will have to run the roller coaster, we need to divide the total number of people waiting in line (84) by the number of people each ride can seat, which is the number of cars (7) multiplied by the number of people each car seats (2) = 7 * 2 = 14.\n",
      "\n",
      "84 ÷ 14 = 6.\n",
      "\n",
      "Therefore, the ride operator will have to run the roller coaster 6 times to give everyone a turn.\n",
      "-------------------- Question:\n",
      "Layla is feeding her pet fish. She has two Goldfish which each get one teaspoon of fish food. Her 3 Swordtails each get 2 teaspoons of food. Her 8 Guppies each eat half a teaspoon of food. How much food does she have to give to her fish in total? \n",
      "Answer:\n",
      "12 \n",
      "Response:\n",
      "To find the total amount of food Layla's fish need, we need to add the food needed for each type of fish.\n",
      "\n",
      "For the Goldfish: Since there are 2 Goldfish and each needs 1 teaspoon, the total food needed for Goldfish is 2 * 1 = 2 teaspoons.\n",
      "\n",
      "For the Swordtails: Since there are 3 Swordtails and each needs 2 teaspoons, the total food needed for Swordtails is 3 * 2 = 6 teaspoons.\n",
      "\n",
      "For the Guppies: Since there are 8 Guppies and each needs 0.5 teaspoons, the total food needed for Guppies is 8 * 0.5 = 4 teaspoons.\n",
      "\n",
      "Now, let's add the food needed for all the fish together: 2 (Goldfish) + 6 (Swordtails) + 4 (Guppies) = 12 teaspoons.\n",
      "\n",
      "<answer>12 teaspoons</answer> \n",
      "Extracted:\n",
      "12 teaspoons\n",
      "-------------------- Question:\n",
      "Nina makes one-of-a-kind jewelry and sells it at a local boutique.  She charges $25.00 for her necklaces, $15.00 for bracelets and $10.00 for a pair of earrings.  Over the weekend, she sold 5 necklaces, 10 bracelets, 20 earrings, and received 2 orders for a complete jewelry ensemble that Nina charged $45.00 for.  How much money did she make over the weekend? \n",
      "Answer:\n",
      "565 \n",
      "Response:\n",
      "To find out how much money Nina made over the weekend, we need to calculate the total amount of money she made from each item type and add it to the amount she made from the complete jewelry ensemble.\n",
      "\n",
      "From necklaces: 5 necklaces * $25.00 per necklace = $125.00\n",
      "From bracelets: 10 bracelets * $15.00 per bracelet = $150.00\n",
      "From earrings: 20 earrings * $10.00 per pair = $200.00\n",
      "From complete jewelry ensemble: 2 ensembles * $45.00 per ensemble = $90.00\n",
      "\n",
      "Now, add the amounts together: $125.00 + $150.00 + $200.00 + $90.00 = $565.00\n",
      "\n",
      "Nina made $565.00 over the weekend. \n",
      "Extracted:\n",
      "To find out how much money Nina made over the weekend, we need to calculate the total amount of money she made from each item type and add it to the amount she made from the complete jewelry ensemble.\n",
      "\n",
      "From necklaces: 5 necklaces * $25.00 per necklace = $125.00\n",
      "From bracelets: 10 bracelets * $15.00 per bracelet = $150.00\n",
      "From earrings: 20 earrings * $10.00 per pair = $200.00\n",
      "From complete jewelry ensemble: 2 ensembles * $45.00 per ensemble = $90.00\n",
      "\n",
      "Now, add the amounts together: $125.00 + $150.00 + $200.00 + $90.00 = $565.00\n",
      "\n",
      "Nina made $565.00 over the weekend.\n",
      "-------------------- Question:\n",
      "The Early Bird Dinner offered dinner meals at half off the menu price if you eat between 2-4 pm.  Curtis ordered the Salisbury Steak that costs $16.00 and Rob ordered the Chicken Fried Steak at $18.00.  If they ate at 3 pm, what was the cost of their total bill? \n",
      "Answer:\n",
      "17 \n",
      "Response:\n",
      "To find the cost of their total bill, we need to calculate the discounted prices of each meal and then add them together.\n",
      "\n",
      "Since they ate between 2-4 pm, both Curtis and Rob received the half-off discount.\n",
      "\n",
      "Curtis ordered the Salisbury Steak for $16.00 and received a half-off discount:\n",
      "Curtis' discounted price = $16.00 * 0.5 = $8.00\n",
      "\n",
      "Rob ordered the Chicken Fried Steak for $18.00 and received a half-off discount:\n",
      "Rob's discounted price = $18.00 * 0.5 = $9.00\n",
      "\n",
      "Now, we add the discounted prices together:\n",
      "Total bill = Curtis' discounted price + Rob's discounted price\n",
      "Total bill = $8.00 + $9.00\n",
      "Total bill = $17.00\n",
      "\n",
      "Therefore, the cost of their total bill is $17.00. \n",
      "Extracted:\n",
      "To find the cost of their total bill, we need to calculate the discounted prices of each meal and then add them together.\n",
      "\n",
      "Since they ate between 2-4 pm, both Curtis and Rob received the half-off discount.\n",
      "\n",
      "Curtis ordered the Salisbury Steak for $16.00 and received a half-off discount:\n",
      "Curtis' discounted price = $16.00 * 0.5 = $8.00\n",
      "\n",
      "Rob ordered the Chicken Fried Steak for $18.00 and received a half-off discount:\n",
      "Rob's discounted price = $18.00 * 0.5 = $9.00\n",
      "\n",
      "Now, we add the discounted prices together:\n",
      "Total bill = Curtis' discounted price + Rob's discounted price\n",
      "Total bill = $8.00 + $9.00\n",
      "Total bill = $17.00\n",
      "\n",
      "Therefore, the cost of their total bill is $17.00.\n",
      "-------------------- Question:\n",
      "Boston had .5 feet of snow on the first day of winter.  The next day they got an additional 8 inches.  Over the next 2 days, 2 inches of the snow melted.  On the fifth day, they received another 2 times the amount of snow they received on the first day.  How many feet of snow do they now have? \n",
      "Answer:\n",
      "2 \n",
      "Response:\n",
      "First, we need to convert all measurements to the same unit.  There are 12 inches in one foot.  So the initial.5 feet of snow is equal to.5 feet * 12 inches per foot = 6 inches.  \n",
      "\n",
      "The next day they got an additional 8 inches.\n",
      "\n",
      "Over the next 2 days, 2 inches of the snow melted, so the amount remaining after this is (6 + 8) - 2 = 12 inches.\n",
      "\n",
      "On the fifth day, they received another 2 times the amount of snow they received on the first day. So the amount they received on the fifth day is 2 * 6 = 12 inches.\n",
      "\n",
      "The total amount of snow now is 12 + 12 = 24 inches.\n",
      "\n",
      "Since there are 12 inches in one foot, we convert 24 inches to feet by dividing by 12: 24 / 12 = 2 feet \n",
      "Extracted:\n",
      "First, we need to convert all measurements to the same unit.  There are 12 inches in one foot.  So the initial.5 feet of snow is equal to.5 feet * 12 inches per foot = 6 inches.  \n",
      "\n",
      "The next day they got an additional 8 inches.\n",
      "\n",
      "Over the next 2 days, 2 inches of the snow melted, so the amount remaining after this is (6 + 8) - 2 = 12 inches.\n",
      "\n",
      "On the fifth day, they received another 2 times the amount of snow they received on the first day. So the amount they received on the fifth day is 2 * 6 = 12 inches.\n",
      "\n",
      "The total amount of snow now is 12 + 12 = 24 inches.\n",
      "\n",
      "Since there are 12 inches in one foot, we convert 24 inches to feet by dividing by 12: 24 / 12 = 2 feet\n",
      "-------------------- Question:\n",
      "At Hank’s cafe, he sells big stack pancakes which have 5 pancakes and short stack pancakes which have 3 pancakes.  If 9 customers order the short stack and 6 customers order the big stack, how many pancakes does Hank need to make? \n",
      "Answer:\n",
      "57 \n",
      "Response:\n",
      "To find the total number of pancakes Hank needs to make, we need to multiply the number of short stacks by 3 and the number of big stacks by 5. Then, we add the two results together.\n",
      "\n",
      "Number of short stacks * pancakes per stack = 9 * 3 = 27\n",
      "Number of big stacks * pancakes per stack = 6 * 5 = 30\n",
      "Total number of pancakes = 27 + 30 = 57\n",
      "\n",
      "Hank needs to make 57 pancakes. \n",
      "Extracted:\n",
      "To find the total number of pancakes Hank needs to make, we need to multiply the number of short stacks by 3 and the number of big stacks by 5. Then, we add the two results together.\n",
      "\n",
      "Number of short stacks * pancakes per stack = 9 * 3 = 27\n",
      "Number of big stacks * pancakes per stack = 6 * 5 = 30\n",
      "Total number of pancakes = 27 + 30 = 57\n",
      "\n",
      "Hank needs to make 57 pancakes.\n",
      "-------------------- Question:\n",
      "Mary bought a packet of 1500 stickers. She shared them between Susan, Andrew and Sam in the ratio 1:1:3 respectively. If Sam gave Andrew two-thirds of his own share, how many stickers does Andrew now have? \n",
      "Answer:\n",
      "900 \n",
      "Response:\n",
      "Let's break this problem down step by step.\n",
      "\n",
      "First, we divide the total number of stickers (1500) between Mary, Susan, and Andrew in the ratio 1:1:3. The parts in the ratio add up to 1 + 1 + 3 = 5.\n",
      "\n",
      "We assume the common ratio unit is x. So, the number of stickers shared with Susan, Andrew, and Sam are:\n",
      "- Susan: x\n",
      "- Andrew: x\n",
      "- Sam: 3x\n",
      "\n",
      "Since the total number of stickers is 1500, the equation becomes: x + x + 3x = 1500\n",
      "Combine like terms: 5x = 1500\n",
      "Divide both sides by 5: x = 300\n",
      "\n",
      "Now that we know the value of x, we can calculate the number of stickers each person originally received:\n",
      "- Susan: x = 300\n",
      "- Andrew: x = 300\n",
      "- Sam: 3x = 3 \n",
      "Extracted:\n",
      "Let's break this problem down step by step.\n",
      "\n",
      "First, we divide the total number of stickers (1500) between Mary, Susan, and Andrew in the ratio 1:1:3. The parts in the ratio add up to 1 + 1 + 3 = 5.\n",
      "\n",
      "We assume the common ratio unit is x. So, the number of stickers shared with Susan, Andrew, and Sam are:\n",
      "- Susan: x\n",
      "- Andrew: x\n",
      "- Sam: 3x\n",
      "\n",
      "Since the total number of stickers is 1500, the equation becomes: x + x + 3x = 1500\n",
      "Combine like terms: 5x = 1500\n",
      "Divide both sides by 5: x = 300\n",
      "\n",
      "Now that we know the value of x, we can calculate the number of stickers each person originally received:\n",
      "- Susan: x = 300\n",
      "- Andrew: x = 300\n",
      "- Sam: 3x = 3\n",
      "-------------------- Question:\n",
      "Milo can roll downhill on his skateboard at twice the speed that he can run.  And Milo's best friend, Cory, can drive his wheelchair at twice the speed that Milo can roll downhill on his skateboard.  If Cory always drives his wheelchair at 12 miles per hour, how many miles can Milo run in two hours? \n",
      "Answer:\n",
      "6 \n",
      "Response:\n",
      "Let's break this problem down step by step:\n",
      "\n",
      "1. Since Milo rolls downhill on his skateboard at twice the speed he can run, let's call Milo's running speed 'x'. Then, his downhill skateboard speed would be 2x.\n",
      "\n",
      "2. Cory drives his wheelchair at twice the speed Milo can roll downhill on his skateboard, so Cory's speed would be 2(2x) = 4x.\n",
      "\n",
      "3. We are given that Cory drives his wheelchair at 12 miles per hour. Since Cory's speed is 4x, we can set up an equation: 4x = 12.\n",
      "4. Solving for x, we divide both sides of the equation by 4: x = 12/4 = 3. This means Milo can run at 3 miles per hour.\n",
      "\n",
      "5. Since Milo can run at 3 miles per hour, in two hours, Milo can run 3 * 2 = 6 miles.\n",
      "\n",
      "<answer>\n",
      "6 miles\n",
      " \n",
      "Extracted:\n",
      "6 miles\n",
      "-------------------- Question:\n",
      "Connie is trying to remember when her grandmother was born. She knows her grandmother's older brother was born in 1932, her older sister was born in 1936, and the gap between her grandmother and her sister is twice the gap between the older brother and the older sister. What year was Connie's grandma born? \n",
      "Answer:\n",
      "1944 \n",
      "Response:\n",
      "reasoning\n",
      "Let's denote the year Connie's grandmother was born as G, the year her older sister was born as S, and the year her older brother was born as B. We know that S = 1936, B = 1932, and G - S = 2 * (S - B).\n",
      "\n",
      "We can start by calculating the gap between S and B:\n",
      "S - B = 1936 - 1932 = 4\n",
      "\n",
      "Since G - S = 2 * (S - B), we can plug in the values:\n",
      "G - S = 2 * (4)\n",
      "G - S = 8\n",
      "\n",
      "Now, we add S to both sides to isolate G:\n",
      "G = S + 8\n",
      "G = 1936 + 8\n",
      "G = 1944\n",
      "\n",
      "</reasoning>\n",
      "<answer>\n",
      "1944 \n",
      "Extracted:\n",
      "1944\n",
      "-------------------- Question:\n",
      "The price per organic egg is 50 cents. The price of a tray of eggs that contains 30 eggs is $12. How much can you save, in cents, per egg if you buy a tray versus individual eggs? \n",
      "Answer:\n",
      "10 \n",
      "Response:\n",
      "To find the cost per egg from the tray, we need to divide the price of the tray by the number of eggs in the tray. \n",
      "\n",
      "The price of the tray is $12, and it contains 30 eggs. \n",
      "\n",
      "Cost per egg from tray = $12 / 30 = $0.40 = 40 cents.\n",
      "\n",
      "The price of buying individual eggs is 50 cents per egg.\n",
      "\n",
      "To find the savings per egg, we subtract the cost per egg from the tray from the cost per individual egg. \n",
      "\n",
      "Savings per egg = 50 cents - 40 cents = 10 cents\n",
      "\n",
      "The answer is 10. \n",
      "Extracted:\n",
      "To find the cost per egg from the tray, we need to divide the price of the tray by the number of eggs in the tray. \n",
      "\n",
      "The price of the tray is $12, and it contains 30 eggs. \n",
      "\n",
      "Cost per egg from tray = $12 / 30 = $0.40 = 40 cents.\n",
      "\n",
      "The price of buying individual eggs is 50 cents per egg.\n",
      "\n",
      "To find the savings per egg, we subtract the cost per egg from the tray from the cost per individual egg. \n",
      "\n",
      "Savings per egg = 50 cents - 40 cents = 10 cents\n",
      "\n",
      "The answer is 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=2.3078780293062096e-05, metrics={'train_runtime': 929.1762, 'train_samples_per_second': 0.022, 'train_steps_per_second': 0.022, 'total_flos': 0.0, 'train_loss': 2.3078780293062096e-05})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        xmlcount_reward_func,\n",
    "        soft_format_reward_func,\n",
    "        strict_format_reward_func,\n",
    "        int_reward_func,\n",
    "        correctness_reward_func,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.62s/it, est. speed input: 1.65 toks/s, output: 20.07 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Calculating pi is a complex task that requires a combination of mathematical formulas and computational algorithms. Here are a few ways to calculate pi:\\n\\n**Method 1: Archimedes' Approximation**\\n\\nArchimedes, a Greek mathematician, used the Pythagorean theorem to approximate pi in the 3rd century BC. His method is based on the following formula:\\n\\npi (π) ≈ (a / c)\\n\\nwhere a and b are the lengths of the sides of a regular hexagon inscribed in a circle, and c is the diameter of the circle.\\n\\nUsing this method, Archimedes approximated pi as:\\n\\npi (π) ≈ 3.1418\\n\\n**Method 2: Leibniz Formula**\\n\\nGottfried Wilhelm Leibniz, a German mathematician, discovered a series of formulas for calculating pi in the 17th century. One of his formulas is:\\n\\npi (π) = 4 * (1 - 1/3 + 1/5 - 1/7 + 1/9 - ...)\\n\\nThis formula is an infinite series, and the more terms you add, the more accurate the approximation of pi will be.\\n\\n**Method 3: Calculus**\\n\\nUsing calculus, we can approximate pi using the following formula:\\n\\npi (π) = ∫(1 / (1 + x^2)) dx from 0 to 1\\n\\nThis integral can be evaluated numerically using various numerical methods, such as the trapezoidal rule or Simpson's rule.\\n\\n**Method 4: Computational Algorithms**\\n\\nModern computers can calculate pi using various computational algorithms, such as:\\n\\n1.  Bailey-Borwein-Plouffe (BBP) formula: This formula is a spigot algorithm that uses a series of arithmetic operations to calculate pi.\\n2. Gauss-Legendre algorithm: This algorithm uses a recursive formula to calculate pi.\\n3. Chudnovsky algorithm: This algorithm uses a series of arithmetic operations to calculate pi.\\n\\nHere's an example of how to calculate pi using the BBP formula in Python:\\n```python\\nimport math\\n\\ndef bbp_pi(n):\\n    pi = 0.0\\n    for k in range(n):\\n        pi += 1/(16**k)*(\\n            4/(8*k+1) -\\n            2\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 推理\n",
    "# 现在让我们尝试刚刚训练的模型！首先，尝试未经过GRPO训练的模型：\n",
    "\n",
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    top_p = 0.95,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    [text],\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = None,\n",
    ")[0].outputs[0].text\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_lora(\"grpo_saved_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.35s/it, est. speed input: 2.61 toks/s, output: 19.36 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The calculation of pi (π) is an ongoing effort in mathematics, and there is no single, definitive formula to compute it exactly. However, I can provide you with an approximation of pi using various methods.\\n\\nOne of the simplest methods to calculate pi is the Leibniz formula, which is a infinite series:\\n\\nπ/4 = 1 - 1/3 + 1/5 - 1/7 + 1/9 - ...\\n\\nThis series is an infinite sum, and the approximation gets better with more terms. However, this method is not the most efficient way to calculate pi.\\n\\nA more efficient method is the Bailey-Borwein-Plouffe (BBP) formula, which is a spigot algorithm for computing any base-b representation of pi:\\n\\nπ = Σ (1/(16^k)) * ((4/(8k+1)) - (2/(8k+4)) - (1/(8k+5)) - (1/(8k+6)))\\n\\nThis formula is more efficient than the Leibniz formula and can be used to calculate pi up to a large number of decimal places.\\n\\nAnother method to calculate pi is using the Monte Carlo method, which is based on random sampling:\\n\\nπ = (number of points inside the circle) / (number of total points)\\n\\nThis method is simple and can be used to estimate pi, but it is not as accurate as other methods.\\n\\nTo give you an accurate approximation of pi, I will use the BBP formula and calculate it up to 10 decimal places:\\n\\nπ ≈ 3.141592654\\n\\nHowever, this is not the most accurate calculation of pi. As of my knowledge cutoff in 2023, the current record for the most accurate calculation of pi is held by the team of mathematicians and computer scientists who used a supercomputer to calculate pi to over 31.4 trillion digits!\\n\\nHere is a more accurate calculation of pi:\\n\\nπ ≈ 3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679\\n\\nKeep in mind that this is an approximation and the actual value of pi goes on forever'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
    "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    top_p = 0.95,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    text,\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
    ")[0].outputs[0].text\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 41.17 out of 78.04 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You are pushing to hub, but you passed your HF username = amerlin.\n",
      "We shall truncate amerlin/unslothllama to unslothllama\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 41.18 out of 78.04 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ca4b63042348ab8303ee63fed429f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e93742863646cbb98b7489868f6b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2e916dfb504424ae3fd97dd0cd14cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f62fbd31e847cfa8c16f9e67473ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e958c346d01420e887d15e8081b8099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aabddce186b4477835b786cc51801bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/amerlin/unslothllama\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 保存为float16以用于VLLM\n",
    "# 我们还支持直接保存为float16。选择merged_16bit用于float16或merged_4bit用于int4。我们还允许lora适配器作为后备。\n",
    "# 使用push_to_hub_merged上传到您的Hugging Face账户！您可以访问https://huggingface.co/settings/tokens获取您的个人令牌。\n",
    "\n",
    "import os  # 需要添加 os 模块\n",
    "# 定义基础路径\n",
    "base_path = os.path.join(\"/mnt/data1\", \"unsloth\")\n",
    "# 确保目录存在（可选添加）\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# 合并到16bit\n",
    "if True: \n",
    "        save_path = os.path.join(base_path, \"model-16bit\")\n",
    "        model.save_pretrained_merged(save_path, tokenizer, save_method = \"merged_16bit\",)\n",
    "if True: \n",
    "       model.push_to_hub_merged(\"amerlin/unslothllama\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
    "\n",
    "# 合并到4bit\n",
    "#if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
    "#if True: model.push_to_hub_merged(\"amerlin/unslothllama\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
    "\n",
    "# 仅LoRA适配器\n",
    "#if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
    "#if True: model.push_to_hub_merged(\"amerlin/unslothllama\", tokenizer, save_method = \"lora\", token = \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GGUF / llama.cpp 转换\n",
    "\n",
    "# 现在我们支持本地保存到GGUF / llama.cpp！我们克隆llama.cpp并默认保存为q8_0。我们允许所有方法，如q4_k_m。使用save_pretrained_gguf进行本地保存，使用push_to_hub_gguf上传到HF。\n",
    "\n",
    "# 一些支持的量化方法（完整列表在我们的Wiki页面上）：\n",
    "\n",
    "# q8_0 - 快速转换。高资源使用，但通常可以接受。\n",
    "# q4_k_m - 推荐。使用Q6_K用于一半的attention.wv和feed_forward.w2张量，其他使用Q4_K。\n",
    "# q5_k_m - 推荐。使用Q6_K用于一半的attention.wv和feed_forward.w2张量，其他使用Q5_K。\n",
    "# [NEW] 要微调并自动导出到Ollama，请尝试我们的Ollama笔记本\n",
    "\n",
    "# 保存为8bit Q8_0\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
    "# 记得访问https://huggingface.co/settings/tokens获取令牌！\n",
    "# 并将hf更改为您的用户名！\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
    "\n",
    "# 保存为16bit GGUF\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
    "\n",
    "# 保存为q4_k_m GGUF\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
    "\n",
    "# 保存为多种GGUF选项 - 如果您想要多种选项，这样更快！\n",
    "if False:\n",
    "    model.push_to_hub_gguf(\n",
    "        \"hf/model\", # 将hf更改为您的用户名！\n",
    "        tokenizer,\n",
    "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
    "        token = \"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在，使用model-unsloth.gguf文件或model-unsloth-Q4_K_M.gguf文件在llama.cpp或基于UI的系统中，如Jan或Open WebUI。您可以在此处安装Jan和Open WebUI\n",
    "\n",
    "# 完成！如果您对Unsloth有任何疑问，我们有一个Discord频道！如果您发现任何错误或想要了解最新的LLM信息，或需要帮助，加入项目等，欢迎加入我们的Discord！\n",
    "\n",
    "# 其他链接：\n",
    "\n",
    "# Llama 3.2 会话笔记本。免费Colab\n",
    "# 保存微调到Ollama。免费笔记本\n",
    "# Llama 3.2 视觉微调 - 放射学用例。免费Colab\n",
    "# 查看我们的文档中的DPO、ORPO、持续预训练、会话微调等笔记本！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
